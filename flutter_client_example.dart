/// EJEMPLO DE CLIENTE FLUTTER PARA VIBEVOICE
/// Equivalente en Dart de lo que est√° haciendo el backend

import 'dart:async';
import 'dart:typed_data';
import 'package:web_socket_channel/web_socket_channel.dart';

/// Funci√≥n principal: Conectarse al servidor VibeVoice y recibir audio en streaming
/// 
/// En Python (backend), esto es lo que hace la funci√≥n `stream()` en app.py
Future<void> vibeVoiceTextToSpeech({
  required String text,
  required String voiceName,
  double cfgScale = 1.5,
  int inferenceSteps = 5,
}) async {
  // PASO 1: Crear conexi√≥n WebSocket (como StreamController.listen())
  final String wsUrl = 'ws://localhost:3000/stream'
      '?text=${Uri.encodeComponent(text)}'
      '&voice=$voiceName'
      '&cfg=$cfgScale'
      '&steps=$inferenceSteps';

  print('üéôÔ∏è Conectando a: $wsUrl');

  try {
    final channel = WebSocketChannel.connect(Uri.parse(wsUrl));

    // PASO 2: Escuchar el stream de audio (como stream.listen())
    // El backend emite chunks de audio en tiempo real
    print('‚úì Conectado! Escuchando stream de audio...');

    channel.stream.listen(
      (data) {
        // 'data' es un chunk de audio PCM16
        // En Flutter har√≠as: _audioPlayer.play(data)
        print('üîä Recibido chunk de audio: ${data.length} bytes');
      },
      onError: (error) {
        print('‚ùå Error en stream: $error');
      },
      onDone: () {
        print('‚úÖ Stream completado. Audio generado completamente.');
      },
    );
  } catch (e) {
    print('‚ùå Error al conectar: $e');
  }
}

/// COMPARACI√ìN CON FLUTTER STREAMS
/// ================================
///
/// En Flutter, esto ser√≠a como:
///
/// ```dart
/// class VibeVoiceService {
///   late StreamController<Uint8List> _audioController;
///   
///   Stream<Uint8List> generateSpeech(String text, String voice) {
///     _audioController = StreamController<Uint8List>();
///     
///     // El backend hace lo mismo: emite chunks de audio
///     // como _audioController.add(audioChunk)
///     
///     return _audioController.stream;
///   }
///   
///   // En tu UI:
///   @override
///   Widget build(BuildContext context) {
///     return StreamBuilder<Uint8List>(
///       stream: service.generateSpeech('Hello', 'Carter'),
///       builder: (context, snapshot) {
///         if (snapshot.hasData) {
///           // Reproduce el audio mientras llega
///           playAudio(snapshot.data!);
///         }
///         return Text('Generando audio...');
///       },
///     );
///   }
/// }
/// ```
///
/// Lo que hace VibeVoice es EXACTAMENTE ESO:
/// - El backend genera tokens de audio continuamente
/// - Los emite en chunks peque√±os (como StreamController.add())
/// - El cliente recibe en tiempo real (como stream.listen())
/// - Puedes reproducir mientras se genera (streaming real-time)

/// PAR√ÅMETROS DISPONIBLES (como configurar un servicio)
/// ====================================================
class VibeVoiceConfig {
  /// Voces disponibles (como opciones en un Dropdown)
  static const List<String> voces = [
    'en-Carter_man',    // Voz por defecto (recomendada)
    'en-Emma_woman',
    'en-Frank_man',
    'en-Grace_woman',
    'en-Mike_man',
    'en-Davis_man',
    'de-Spk0_man',
    'fr-Spk0_man',
    'ja-Spk0_man',
    // ... m√°s voces disponibles
  ];

  /// CFG Scale: controla cu√°nto "sigue" al texto
  /// 1.0 = Sin seguimiento (audio gen√©rico)
  /// 1.5 = Balance perfecto (RECOMENDADO)
  /// 3.0 = Sigue mucho el texto (puede ser menos natural)
  static const double cfgScaleDefault = 1.5;

  /// Pasos de inferencia: m√°s = mejor calidad, m√°s lento
  /// 5 = Muy r√°pido, buena calidad (RECOMENDADO)
  /// 10 = Mejor calidad, m√°s lento
  static const int inferenceStepsDefault = 5;

  /// Latencia esperada en ms (primera vez que escuchas audio)
  static const int firstAudioLatencyMs = 300; // ~300ms
}

/// EJEMPLO DE USO EN TU APP FLUTTER
/// =================================
class VibeVoiceDemo {
  Future<void> demoB√°sico() async {
    // 1Ô∏è‚É£ Texto a convertir
    const String texto = 'Hola, este es un test de s√≠ntesis de voz en tiempo real';

    // 2Ô∏è‚É£ Voz a usar
    const String voz = 'en-Carter_man';

    // 3Ô∏è‚É£ Llamar la funci√≥n (como hacer un GET request)
    await vibeVoiceTextToSpeech(
      text: texto,
      voiceName: voz,
      cfgScale: 1.5,
      inferenceSteps: 5,
    );

    // El audio empieza a llegar en ~300ms
    // Puedes reproducirlo mientras se genera
  }
}

/// MODO "BUS" vs "REALTIME"
/// =========================
/// 
/// ANTES (Modo BUS):
/// - El servidor estaba corriendo pero sin procesar nada
/// - Era como tener una EventBus que escucha pero nadie env√≠a eventos
/// 
/// AHORA (Modo REALTIME):
/// - El servidor est√° activo y esperando peticiones WebSocket
/// - Cuando env√≠as texto ‚Üí genera audio continuamente
/// - Es como un StreamController que emite datos en tiempo real
/// 
/// Lo que necesitas hacer:
/// 1. Enviar texto al WebSocket
/// 2. Escuchar los chunks de audio que llegan
/// 3. Reproducirlos en paralelo (streaming real-time)

void main() {
  // Esto es lo que har√≠as en tu app Flutter:
  final demo = VibeVoiceDemo();
  demo.demoB√°sico();
}
